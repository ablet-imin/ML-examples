{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN with Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This net work has only one hiden layer (just wor test).  \n",
    "input is x,  output os y, the hiden layer is h   \n",
    "<pre>\n",
    "formula: h = x.w1   \n",
    "         y = h.w2  \n",
    "         where w1 and w2 are weight matrices  \n",
    "         input x has dimensio D (vector), hiden layerd has dimention H (vector)   \n",
    "         so w1 is D*H matrix. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "#I followed the example from pytorch. My goal is to use pytorch in final version of my examples\n",
    "#But I reduced some dimensions, it can run faster! \n",
    "N , D_in, H, D_out = 64, 200, 50, 2\n",
    "\n",
    "#Create random inputs and outputs (sometimes this called labels).\n",
    "#Here N is so called batch size, which means we use N input vector\n",
    "#at in once, each vector has D_in dimension. So x is (N*D_in) tensor.\n",
    "x = np.random.randn(N, D_in)\n",
    "#y = np.random.randn(N, D_out) # label is also random\n",
    "y = np.random.randint(D_out, size=(N, D_out))\n",
    "\n",
    "#Random initialize weights\n",
    "w1 = np.random.randn(D_in, H) # transform input to hiden layer\n",
    "w2 = np.random.randn(H, D_out) # transform hiden layer to output\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.4488075151365527e-24\n",
      "10 2.3271636104815655e-24\n",
      "20 2.2116856152251088e-24\n",
      "30 2.108717031077001e-24\n",
      "40 2.0203929470550773e-24\n",
      "50 1.9345906664578706e-24\n",
      "60 1.867746919758469e-24\n",
      "70 1.7978793921721577e-24\n",
      "80 1.7286249759095503e-24\n",
      "90 1.667714424641639e-24\n",
      "100 1.605715310035769e-24\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5 # not too samle, so it can go faster!\n",
    "\n",
    "#I don't want to cycle 500 times as it is\n",
    "#in pytorch example.\n",
    "for t in range(101):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    \n",
    "    #loss, least square\n",
    "    loss = np.square(y_pred - y).sum() # minimize squared difference\n",
    "    \n",
    "    if t%10 ==0: print(t, loss)\n",
    "    #update weights\n",
    "    #we need gradiants of w1 and w1\n",
    "    grad_y_pred = 2.0 * (y_pred - y) # grad of loss\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0 \n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    #we got gras of w1 and w2\n",
    "    #update w1 and w2\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1 #take one step backward.\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03412401  0.77216904  0.07845967 ...  0.72616532  0.39055696\n",
      "  -1.12214354]\n",
      " [-0.80250894  0.64083233  1.88856808 ... -0.32817799  1.10335291\n",
      "   1.74940804]\n",
      " [ 0.24793685  0.50379039 -0.06066793 ...  0.05341769 -1.78427379\n",
      "  -1.51014449]\n",
      " ...\n",
      " [-0.2867163   0.41560065 -0.82906762 ...  1.34825444  1.37056261\n",
      "  -0.47483842]\n",
      " [ 1.42517693 -0.2000761  -0.02175257 ... -0.80528438 -0.26491741\n",
      "  -0.64096057]\n",
      " [ 1.51817776 -0.52302678 -0.3948161  ... -0.02867154  0.70265549\n",
      "  -0.29461816]]\n"
     ]
    }
   ],
   "source": [
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.203125\n"
     ]
    }
   ],
   "source": [
    "#Test acurracy\n",
    "#for original inputs\n",
    "h = x.dot(w1)\n",
    "h_relu = np.maximum(h, 0)\n",
    "y_pred = h_relu.dot(w2)\n",
    "result_original = np.argmax(y_pred, axis=1)*np.argmax(y, axis=1)\n",
    "print(result_original.sum()/len(result_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    }
   ],
   "source": [
    "#for other random inputs\n",
    "test_x = np.random.randn(N, D_in)\n",
    "#y = np.random.randn(N, D_out) # label is also random\n",
    "test_y = np.random.randint(D_out, size=(N, D_out))\n",
    "\n",
    "h = test_x.dot(w1)\n",
    "h_relu = np.maximum(h, 0)\n",
    "y_pred = h_relu.dot(w2)\n",
    "\n",
    "result = np.argmax(y_pred, axis=1)*np.argmax(test_y, axis=1)\n",
    "print(result.sum()/len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
